# huggingface-agents-final-project

Final project of Hugging Face Agents Course

---

## What is GAIA?

[GAIA](https://huggingface.co/papers/2311.12983) is a benchmark designed to evaluate AI assistants on real-world tasks that require a combination of core capabilitiesâ€”such as reasoning, multimodal understanding, web browsing, and proficient tool use.

It features 466 carefully curated questions that are conceptually simple for humans, yet remarkably challenging for current AI systems.

**Performance gap:**
- Humans: ~92% success rate
- GPT-4 with plugins: ~15%
- Deep Research (OpenAI): 67.36% on the validation set

GAIA highlights the current limitations of AI models and provides a rigorous benchmark to evaluate progress toward truly general-purpose AI assistants.

---

## ðŸŒ± GAIAâ€™s Core Principles

- **Real-world difficulty:** Tasks require multi-step reasoning, multimodal understanding, and tool interaction.
- **Human interpretability:** Tasks are conceptually simple and easy for humans to follow.
- **Non-gameability:** Correct answers demand full task execution, making brute-forcing ineffective.
- **Simplicity of evaluation:** Answers are concise, factual, and unambiguousâ€”ideal for benchmarking.

